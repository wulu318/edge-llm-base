# 文件名: create_spec.py
# 这个脚本用于生成一个精确的 .spec 配置文件，以解决 C++ 库打包失败的问题。

import sys
import os
import site

def find_package_path(package_name):
    """在 Python 环境中查找已安装包的路径。"""
    paths = site.getsitepackages()
    if site.getusersitepackages() and site.getusersitepackages() not in paths:
        paths.append(site.getusersitepackages())
    
    for site_dir in paths:
        potential_path = os.path.join(site_dir, package_name)
        if os.path.isdir(potential_path):
            return potential_path
    raise FileNotFoundError(f"Could not find package: '{package_name}'")

try:
    # 1. 自动查找 llama_cpp 包的安装路径
    llama_cpp_path = find_package_path('llama_cpp')
    print(f"Found llama_cpp package at: {llama_cpp_path}")

    # 2. 构建其内部 lib 目录的路径
    llama_cpp_lib_path = os.path.join(llama_cpp_path, 'lib')
    
    # 3. 检查 lib 目录是否存在，这是关键一步
    if not os.path.isdir(llama_cpp_lib_path):
        raise FileNotFoundError(f"Required 'lib' folder not found in {llama_cpp_path}!")

    # 4. 创建 PyInstaller 需要的 (源路径, 目标路径) 元组
    # 我们要将 llama_cpp/lib 文件夹，完整地复制到打包目录下的 llama_cpp/lib
    llama_lib_data_tuple = (llama_cpp_lib_path, 'llama_cpp/lib')

    # 5. 使用 f-string 定义 .spec 文件的内容模板
    spec_content = f"""
# -*- mode: python ; coding: utf-8 -*-
# Auto-generated by create_spec.py

a = Analysis(
    ['edge_llm_base.py'],
    pathex=[],
    binaries=[],
    # datas: 包含非二进制的数据文件
    datas=[
        ('qwen3-0.6b-q4.gguf', '.'),
        {repr(llama_lib_data_tuple)}  # <-- 决定性的修复！
    ],
    # hiddenimports: 强制包含 PyInstaller 可能找不到的库
    hiddenimports=[
        'uvicorn.lifespan.on',
        'uvicorn.loops.auto',
        'uvicorn.protocols.http.auto',
        'uvicorn.protocols.websockets.auto',
        'fastapi',
        'sse_starlette',
        'pydantic_settings'
    ],
    hookspath=[],
    runtime_hooks=[],
    excludes=[],
    win_no_prefer_redirects=False,
    win_private_assemblies=False,
    noarchive=False
)
pyz = PYZ(a.pure, a.zipped_data)

exe = EXE(
    pyz,
    a.scripts,
    [],
    exclude_binaries=True,
    name='edge_llm_base',
    debug=False,
    bootloader_ignore_signals=False,
    strip=False,
    upx=True,
    console=False, # 对应 --windowed
    icon=None
)

coll = COLLECT(
    exe,
    a.binaries,
    a.zipfiles,
    a.datas,
    strip=False,
    upx=True,
    upx_exclude=[],
    name='edge_llm_base'
)
"""

    # 6. 将生成的内容写入 build.spec 文件
    with open('build.spec', 'w', encoding='utf-8') as f:
        f.write(spec_content)
    print("build.spec file created successfully, including path to llama_cpp/lib.")

except Exception as e:
    print(f"Error creating .spec file: {e}")
    sys.exit(1)

