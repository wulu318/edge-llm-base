name: Build Edge LLM Base Installers with Model

on: [push, workflow_dispatch]

jobs:
  build-windows:
    runs-on: windows-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        id: setup-python # 给这个步骤一个 id，方便后面引用
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - name: Install dependencies
        run: |
          pip install llama-cpp-python[server] pystray pillow pyinstaller
      
      # 关键改动: 使用 --add-binary 强制打包 python.exe
      - name: Build PyInstaller executable
        shell: pwsh
        run: |
          # 获取 python.exe 的完整路径
          $pythonPath = (Get-Command python).Source
          pyinstaller --onedir --windowed --name edge_llm_base `
            --hidden-import=llama_cpp.server `
            --add-binary "$pythonPath;." `
            edge_llm_base.py

      - name: Prepare build directory
        run: |
          Invoke-WebRequest -Uri https://huggingface.co/a5656789/qwen3-0.6b-q4/resolve/main/qwen3-0.6b-q4.gguf -OutFile dist/edge_llm_base/qwen3-0.6b-q4.gguf
          Copy-Item server_runner.py -Destination dist/edge_llm_base/
      
      - name: Install NSIS
        run: choco install nsis -y
      
      - name: Create NSIS installer script
        run: |
          # NSIS 脚本部分无需改动
          echo '!define PRODUCT_NAME "Edge LLM Base"' > installer.nsi
          # ... (省略和之前版本相同的 NSIS 代码) ...
          echo '  File /r "dist\edge_llm_base\*"' >> installer.nsi
          # ...
          echo '  RMDir /r "$INSTDIR"' >> installer.nsi
          # ...
          echo 'SectionEnd' >> installer.nsi
      - name: Build NSIS installer
        run: makensis installer.nsi
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: windows-installer
          path: setup.exe

  build-linux-x86:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ruby-full wget ninja-build libappindicator3-1 gir1.2-appindicator3-0.1
          sudo gem install fpm
          pip install llama-cpp-python[server] pystray pillow pyinstaller
      
      # 关键改动: 使用 --add-binary 强制打包 python 解释器
      - name: Build PyInstaller executable
        run: |
          python_path=$(which python)
          pyinstaller --onedir --name edge_llm_base \
            --hidden-import=llama_cpp.server \
            --add-binary "$python_path:." \
            edge_llm_base.py
      
      - name: Prepare build directory
        run: |
          wget https://huggingface.co/a5656789/qwen3-0.6b-q4/resolve/main/qwen3-0.6b-q4.gguf -O dist/edge_llm_base/qwen3-0.6b-q4.gguf
          cp server_runner.py dist/edge_llm_base/
      
      - name: Create post-install script for fpm
        run: |
          echo '#!/bin/sh' > post-install.sh
          echo 'ln -sf /opt/edge-llm-base/edge_llm_base /usr/local/bin/edge_llm_base' >> post-install.sh
          chmod +x post-install.sh
      
      - name: Build deb package with fpm
        run: |
          fpm -s dir -t deb -n edge-llm-base -v 1.0 \
            --prefix /opt/edge-llm-base \
            --description "Edge LLM Base for Qwen3 with Model" \
            --after-install ./post-install.sh \
            -C dist/edge_llm_base \
            .
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: linux-x86-deb
          path: ./*.deb

  build-linux-arm64:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Set up QEMU for ARM64
        uses: docker/setup-qemu-action@v3
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      - name: Build in ARM64 Docker
        run: |
          docker run --rm --privileged -v $(pwd):/app -w /app --platform=linux/arm64 \
            ubuntu:22.04 bash -c "
              set -e
              apt-get update
              apt-get install -y python3 python3-pip ruby-full wget ninja-build libappindicator3-1 gir1.2-appindicator3-0.1
              gem install fpm
              pip install llama-cpp-python[server] pystray pillow pyinstaller --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cpu
              
              # 关键改动: 使用 --add-binary 强制打包 python 解释器
              python_path=\$(which python3)
              pyinstaller --onedir --name edge_llm_base \
                --hidden-import=llama_cpp.server \
                --add-binary \"\$python_path:.\" \
                edge_llm_base.py
              
              wget https://huggingface.co/a5656789/qwen3-0.6b-q4/resolve/main/qwen3-0.6b-q4.gguf -O dist/edge_llm_base/qwen3-0.6b-q4.gguf
              cp server_runner.py dist/edge_llm_base/

              echo '#!/bin/sh' > post-install.sh
              echo 'ln -sf /opt/edge-llm-base/edge_llm_base /usr/local/bin/edge_llm_base' >> post-install.sh
              chmod +x post-install.sh

              fpm -s dir -t deb -n edge-llm-base -v 1.0 \
                --architecture arm64 \
                --prefix /opt/edge-llm-base \
                --description 'Edge LLM Base for Qwen3 with Model' \
                --after-install ./post-install.sh \
                -C dist/edge_llm_base \
                .
            "
      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: linux-arm64-deb
          path: ./*_arm64.deb
